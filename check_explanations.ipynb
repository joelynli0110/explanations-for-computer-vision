{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxsDu4-dbPOP",
        "outputId": "0d514568-8eb7-4e84-959d-df058a86ac3d"
      },
      "source": [
        "# google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gT3j9Zq6Lza",
        "outputId": "98b72c7d-e031-432c-d45d-ff00db55b28a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "import os\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "os.chdir(\"/content/gdrive/MyDrive/xai-lab/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwKbbfsThMSm",
        "outputId": "4c79566b-88af-499f-e95d-38e2023a86f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lime in /usr/local/lib/python3.7/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lime) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from lime) (1.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from lime) (3.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lime) (4.62.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lime) (1.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from lime) (0.18.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (1.2.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.6.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (7.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->lime) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install lime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLszfBip6Lzd"
      },
      "source": [
        "# Object detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Hv8aPZzabVcY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor, fasterrcnn_resnet50_fpn\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from lime.lime_image import LimeImageExplainer\n",
        "from src.faster_rcnn import fasterrcnn_resnet18_fpn\n",
        "\n",
        "from src.utils import jaccard\n",
        "\n",
        "# device = 'cpu'\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# our dataset has two classes only - background and person\n",
        "num_classes = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-IRPo_rbmIH",
        "outputId": "5d8592d8-8ff8-4604-942a-87bbd0b28e6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FasterRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(128, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# load an instance segmentation model pre-trained pre-trained on COCO\n",
        "# model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True, num_classes=num_classes)\n",
        "# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, num_classes=num_classes)\n",
        "model = fasterrcnn_resnet18_fpn(pretrained_backbone=True, num_classes=num_classes)\n",
        "# get number of input features for the classifier\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "# replace the pre-trained head with a new one\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "# load model checkpoint\n",
        "path = os.path.join(os.getcwd(), \"./checkpoints/faster_rcnn_resnet1830_epochs.ckpt\")\n",
        "checkpoint = torch.load(path, map_location=device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "model.to(device) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhSjHrr16Lzg"
      },
      "source": [
        "# PennFudan Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Qp9vqpO-eP73"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"./detection\")\n",
        "from pennfudan_dataset import PennFudanDataset, get_transform\n",
        "\n",
        "# use our dataset and defined transformations\n",
        "dataset = PennFudanDataset('./PennFudanPed', get_transform(train=True))\n",
        "dataset_test = PennFudanDataset('./PennFudanPed', get_transform(train=False))\n",
        "# changing to array\n",
        "\n",
        "\n",
        "# split the dataset in train and test set\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
        "dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3hh6ESKCeSk1"
      },
      "outputs": [],
      "source": [
        "#creating test image\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "4OkaIOfI6Lzj"
      },
      "source": [
        "# COCO Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3Jp1rSs6Lzk"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize the Detection\n",
        "\n"
      ],
      "metadata": {
        "id": "8Jc9Ms2KVRks"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36AZzN80eInN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c135eb-9863-4107-949a-0d07125b14d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ],
      "source": [
        "# pick one image from the test set\n",
        "img, _ = dataset_test[0]\n",
        "# put the model in evaluation mode\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    prediction = model([img.to(device)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7X8J5fW_jzKN"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw\n",
        "\n",
        "result = Image.fromarray(img.mul(255).permute(1, 2, 0).byte().numpy())\n",
        "image = ImageDraw.Draw(result)  \n",
        "\n",
        "for bbox in prediction[0][\"boxes\"]:\n",
        "    image.rectangle(bbox.cpu().numpy().tolist(), outline =\"red\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "OMpgVmR86Lzs",
        "outputId": "f3d8ccd3-f0dd-45ed-a0ba-90ea4d3d746a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1f2f03e476ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.imshow(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szMfm6-n6Lzk"
      },
      "source": [
        "# Explanations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Explainer"
      ],
      "metadata": {
        "id": "b4hKTkAwF88a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kNmfbZWh6Lzl"
      },
      "outputs": [],
      "source": [
        "from src.sodexplainer import SODExplainer\n",
        "explainer_sodex = SODExplainer(model=model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHtvztpN6Lzl"
      },
      "source": [
        "## Lime Explanation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8Dtx7ct6Lzm"
      },
      "outputs": [],
      "source": [
        "image_test = dataset_test[0][0]\n",
        "image_test = image_test.permute(1,2,0).detach().numpy()\n",
        "image_test = image_test.astype('double')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNNWCG6Z6Lzm"
      },
      "outputs": [],
      "source": [
        "explanation = explainer_sodex.get_lime_explanation(image_test,dataset_test[0], num_samples=100000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkwAKXJ8eFIu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from skimage.segmentation import mark_boundaries\n",
        "\n",
        "temp_1, mask_1 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=20, hide_rest=True)\n",
        "temp_2, mask_2 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=200, hide_rest=False)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,15))\n",
        "ax1.imshow(mark_boundaries(temp_1, mask_1))\n",
        "ax2.imshow(mark_boundaries(temp_2, mask_2))\n",
        "ax1.axis('off')\n",
        "ax2.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qju0OQRg6Lzo"
      },
      "source": [
        "## Rise explanation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-9zATj36Lzo",
        "outputId": "0c6a77eb-f9ca-481a-d7be-dfd74a15347f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating masks: 100%|██████████| 10/10 [00:00<00:00, 72.76it/s]\n",
            "Explaining:   0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Explaining: 100%|██████████| 10/10 [00:52<00:00,  5.23s/it]\n"
          ]
        }
      ],
      "source": [
        "image_test = dataset_test[0][0].permute(1,2,0)\n",
        "image_test = image_test.detach().numpy().astype('double')\n",
        "sal, preds, masks = explainer_sodex.get_rise_explanation(torch.from_numpy(image_test), N=10, s=10, p1=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYuehDw-6Lzq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.axis('off')\n",
        "plt.imshow(sal, cmap='jet', alpha=0.8)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K287keuS6Lzs",
        "outputId": "4ad0ce8d-211e-4a9a-b2bf-95c7267edafa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(364, 579)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "sal.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "7eufsnDyUR3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.eval import *"
      ],
      "metadata": {
        "id": "7dll-2RoUjTi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pointing Game Accuracy"
      ],
      "metadata": {
        "id": "FkHE1PX-UZMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Rise explanation for 5 images with N=5 (just for testing)."
      ],
      "metadata": {
        "id": "jmMTRAcdX4Lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_images = 5\n",
        "sals = []\n",
        "for i in range(num_images):\n",
        "  image_test = dataset_test[i][0].permute(1,2,0)\n",
        "  image_test = image_test.detach().numpy().astype('double')\n",
        "  sal, preds, masks = explainer_sodex.get_rise_explanation(torch.from_numpy(image_test), N=5, s=10, p1=0.5) # <- change N later\n",
        "  sals.append(sal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo8ftVfNEcDF",
        "outputId": "1114ab9c-4210-4203-ce8e-505319cbc1e4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating masks: 100%|██████████| 5/5 [00:00<00:00, 58.94it/s]\n",
            "Explaining:   0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Explaining: 100%|██████████| 5/5 [00:26<00:00,  5.21s/it]\n",
            "Generating masks: 100%|██████████| 5/5 [00:00<00:00, 95.57it/s]\n",
            "Explaining: 100%|██████████| 5/5 [00:24<00:00,  4.96s/it]\n",
            "Generating masks: 100%|██████████| 5/5 [00:00<00:00, 87.57it/s]\n",
            "Explaining: 100%|██████████| 5/5 [00:26<00:00,  5.37s/it]\n",
            "Generating masks: 100%|██████████| 5/5 [00:00<00:00, 94.29it/s]\n",
            "Explaining: 100%|██████████| 5/5 [00:30<00:00,  6.06s/it]\n",
            "Generating masks: 100%|██████████| 5/5 [00:00<00:00, 107.29it/s]\n",
            "Explaining: 100%|██████████| 5/5 [00:21<00:00,  4.33s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute pointing game accuracy."
      ],
      "metadata": {
        "id": "Hxdfqf1zYGab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.eval import compute_localization_acc\n",
        "dataset_test = PennFudanDataset('./PennFudanPed', get_transform(train=False))\n",
        "dataset_test = torch.utils.data.Subset(dataset_test, indices[:num_images])\n",
        "evaluate(sals,dataset_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nea1v2OOWPx5",
        "outputId": "dc012d6f-cd88-4022-a85b-c91a39541dd6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "TxsDu4-dbPOP",
        "YLszfBip6Lzd",
        "VhSjHrr16Lzg",
        "4OkaIOfI6Lzj",
        "8Jc9Ms2KVRks",
        "szMfm6-n6Lzk",
        "mHtvztpN6Lzl",
        "qju0OQRg6Lzo"
      ],
      "name": "check_explanations.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}